{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JIRA client\n",
    "from os import environ\n",
    "from atlassian import Jira\n",
    "\n",
    "jira_api_token = environ.get(\"JIRA_TOKEN\", \"\")\n",
    "jira_url = environ.get(\"JIRA_URL\", \"\")\n",
    "client = Jira(url=jira_url, token=jira_api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our local modules\n",
    "from jiraissues import Issue, issue_cache\n",
    "from summarizer import summarize_issue, get_chat_model, rollup_contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epic_to_summarize = \"OCTO-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the existing summaries from the Jira issues\n",
    "child_inputs = []\n",
    "epic = issue_cache.get_issue(client, epic_to_summarize)\n",
    "for child in epic.children:\n",
    "    issue = issue_cache.get_issue(client, child.key)\n",
    "    text = f\"{issue}\\n\"\n",
    "    text += summarize_issue(issue, max_depth=1)\n",
    "    child_inputs.append({\"issue\": issue, \"summary\": text})\n",
    "\n",
    "# Sort the issues by key\n",
    "child_inputs.sort(key=lambda x: x[\"issue\"].key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the individual exec summaries\n",
    "import textwrap\n",
    "llm = get_chat_model(\"meta-llama/llama-3-70b-instruct\", max_new_tokens=2048)\n",
    "for item in child_inputs:\n",
    "    data = f\"\"\"\\\n",
    "{item[\"issue\"]}\n",
    "{item[\"summary\"]}\n",
    "Contributors: {', '.join(c.display_name for c in item[\"issue\"].contributors)}\"\"\"\n",
    "    prompt = f\"\"\"\\\n",
    "Condense the following technical status update into a short, high-level summary for an engineering leader.\n",
    "Focus on the high-level objective, keeping the technical detail to a minimum.\n",
    "Where possible, avoid mentioning specific issue IDs.\n",
    "\n",
    "{data}\n",
    "\n",
    "Please provide your converted summary with no formatting or bullet points:\n",
    "\"\"\"\n",
    "    summary = llm.invoke(prompt, stop=[\"<|endoftext|>\"])\n",
    "    item[\"exec_summary\"] = textwrap.fill(summary).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in child_inputs:\n",
    "    issue = item[\"issue\"]\n",
    "    print(f\"**{issue.key} - {issue.summary}**\")\n",
    "    print(item[\"exec_summary\"])\n",
    "    contributors = sorted(rollup_contributors(item[\"issue\"]), key=lambda x: x.display_name.split()[-1])\n",
    "    if contributors:\n",
    "        print(f\"Contributors: {', '.join([c.display_name for c in contributors])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the overall exec summary\n",
    "prompt = f\"\"\"\\\n",
    "Given the following high-level summaries of our group's work, please provide a short, one-paragraph summary of this initiative for a corporate leader:\n",
    "\n",
    "{\"\\n\".join([item[\"exec_summary\"] for item in child_inputs])}\n",
    "\n",
    "Please provide just the summary paragraph, with no header.\n",
    "\"\"\"\n",
    "paragraph = llm.invoke(prompt, stop=[\"<|endoftext|>\"])\n",
    "print(paragraph.strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
